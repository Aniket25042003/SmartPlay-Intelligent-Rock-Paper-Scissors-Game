# -*- coding: utf-8 -*-
"""rockpaperscissors.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1spMccK8qitCeu4r17nZylwNT0pOz8iuM
"""

import pandas as pd
import os
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical

from google.colab import drive
drive.mount('/content/drive')

train_image_dir = '/content/drive/MyDrive/RockPaperScissors/Data/train'
test_image_dir = '/content/drive/MyDrive/RockPaperScissors/Data/test'
val_image_dir = '/content/drive/MyDrive/RockPaperScissors/Data/valid'

train_csv = '/content/drive/MyDrive/RockPaperScissors/Data/train/_annotations.csv'
test_csv = '/content/drive/MyDrive/RockPaperScissors/Data/test/_annotations.csv'
val_csv = '/content/drive/MyDrive/RockPaperScissors/Data/valid/_annotations.csv'

df_train = pd.read_csv(train_csv)
df_test = pd.read_csv(test_csv)
df_val = pd.read_csv(val_csv)

df_train.head()

def preprocess_data(df, image_dir):
    image_paths = []
    labels = []

    for index, row in df.iterrows():
        filename = row['filename']
        class_name = row['class']
        image_path = os.path.join(image_dir, filename)

        if os.path.exists(image_path):
            image_paths.append(image_path)
            labels.append(class_name)
        else:
            print(f"Warning: Image file '{image_path}' not found.")

    return image_paths, labels

train_image_paths, train_labels = preprocess_data(df_train, train_image_dir)
test_image_paths, test_labels = preprocess_data(df_test, test_image_dir)
val_image_paths, val_labels = preprocess_data(df_val, val_image_dir)

class_mapping = {'Rock': 0, 'Paper': 1, 'Scissors': 2}
train_labels = [class_mapping[train_label] for train_label in train_labels]
test_labels = [class_mapping[test_label] for test_label in test_labels]
val_labels = [class_mapping[val_label] for val_label in val_labels]

num_classes = 3
train_labels = to_categorical(train_labels, num_classes)
test_labels = to_categorical(test_labels, num_classes)
val_labels = to_categorical(val_labels, num_classes)

print(f"Number of training samples: {len(train_image_paths)}")
print(f"Number of validation samples: {len(val_image_paths)}")
print(f"Number of test samples: {len(test_image_paths)}")

import numpy as np
from tensorflow.keras.preprocessing.image import load_img, img_to_array

img_height, img_width = 224, 224

def load_and_preprocess_images(image_paths):
    images = []
    for path in image_paths:
        img = load_img(path, target_size=(img_height, img_width))
        img_array = img_to_array(img) / 255.0
        images.append(img_array)
    return np.array(images)

x_train = load_and_preprocess_images(train_image_paths)
print("Training data shape:", x_train.shape)

x_val = load_and_preprocess_images(val_image_paths)
print("Validation data shape:", x_val.shape)

x_test = load_and_preprocess_images(test_image_paths)
print("Test data shape:", x_test.shape)

# Now import TensorFlow and build/train your model as before
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

# Define your model architecture
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),
    MaxPooling2D((2, 2)),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(num_classes, activation='softmax')
])

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(x_train, train_labels, epochs=2, batch_size=64, validation_data=(x_val, val_labels))

# Evaluate the model on the test set
test_loss, test_accuracy = model.evaluate(x_test, test_labels)
print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')

